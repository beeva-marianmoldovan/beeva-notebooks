{
 "metadata": {
  "name": "",
  "signature": "sha256:017af641e0d36bfc4b3173e3243889fba5b1851dcc17109afda10ab4f2f67584"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Cargo el modelo de word vectors"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import logging\n",
      "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from gensim import corpora, models, similarities\n",
      "import string, unicodedata, re, os"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# ---------------------------------------------------\n",
      "# LOAD MODEL\n",
      "# Ficheros del modelo en diferentes formatos\n",
      "fileModel = '/home/nievesabalos/Escritorio/nlp/datasets/wikipedia/modelo/es_wikipedia.model'  #.model\n",
      "\n",
      "print \"\\nCargo el modelo en .model:\"  \n",
      "print fileModel \n",
      "model = models.Word2Vec.load(fileModel)  # you can continue training with the loaded model!.load(fileModel)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Cargo el modelo en .model:\n",
        "/home/nievesabalos/Escritorio/nlp/datasets/wikipedia/modelo/es_wikipedia.model\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print model.most_similar(\"juegos\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[('olimpicos', 0.7551369071006775), ('medallistas', 0.7083016633987427), ('istmicos', 0.7047864198684692), ('paralimpicos', 0.6982350945472717), ('panamericanos', 0.6951496005058289), ('nemeos', 0.6864862442016602), ('piticos', 0.6621361970901489), ('seul', 0.6553879380226135), ('jjoo', 0.6549515128135681), ('estraton', 0.6477175951004028)]\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Resumen libro"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "INPUT"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def clean(x):\n",
      "   x = unicodedata.normalize('NFKD', x).encode('ascii','ignore').lower()\n",
      "   replace_punctuation = string.maketrans(string.punctuation, ' '*len(string.punctuation))\n",
      "   x = x.translate(replace_punctuation)\n",
      "   x = re.sub('@%$&[\\n/:!,;)()_?\u00bf\u00a1<>]', ' ', x)\n",
      "   x = re.sub(' - ', ' ', x)\n",
      "   x = re.sub(' +',' ', x).strip()\n",
      "   return x\n",
      "\n",
      "documentos = []\n",
      "print documentos\n",
      "def creaConjuntoDocumentos(pathLibros):\n",
      "    for libroFile in os.listdir(pathLibros):\n",
      "        print(\"\\nResumen libro en: \" + pathLibros + libroFile)\n",
      "        lineasDocumento = []\n",
      "        fileName = pathLibros + libroFile\n",
      "        with open(fileName, 'r') as fileData:\n",
      "            print \"Leo datos y preproceso.\"\n",
      "            for lineas in fileData:\n",
      "                #Formatear linea si hace falta aqu\u00ed\n",
      "                lineArray = lineas.split(\".\")\n",
      "                for line in lineArray:\n",
      "                    if len(line) > 1:\n",
      "                        line = line.decode('utf-8')\n",
      "                        line = clean(line) # \u00bf? problemas con gensim y tildes y e\u00f1es...\n",
      "                        if len(line) > 1:\n",
      "                            lineasDocumento.append(line)\n",
      "            # un fichero, un resumen, un documento:\n",
      "            stringDocumento = ' '.join(lineasDocumento)\n",
      "            documentos.append(stringDocumento)\n",
      "            #print documentos\n",
      "            print \"A\u00f1ado a la lista de documentos y cierro fichero.\"\n",
      "            fileData.close()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[]\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "resumenPath = \"/home/nievesabalos/Escritorio/nlp/bookstore/LOS \u00daLTIMOS ESPA\u00d1OLES DE MAUTHAUSEN.txt\"\n",
      "pathLibros = \"/home/nievesabalos/Escritorio/nlp/bookstore/\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "creaConjuntoDocumentos(pathLibros)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Resumen libro en: /home/nievesabalos/Escritorio/nlp/bookstore/MR MERCEDES.txt\n",
        "Leo datos y preproceso.\n",
        "A\u00f1ado a la lista de documentos y cierro fichero.\n",
        "\n",
        "Resumen libro en: /home/nievesabalos/Escritorio/nlp/bookstore/LOS \u00daLTIMOS ESPA\u00d1OLES DE MAUTHAUSEN.txt\n",
        "Leo datos y preproceso.\n",
        "A\u00f1ado a la lista de documentos y cierro fichero.\n",
        "\n",
        "Resumen libro en: /home/nievesabalos/Escritorio/nlp/bookstore/JUEGOS DEL HAMBRE 3 SINSAJO.txt\n",
        "Leo datos y preproceso.\n",
        "A\u00f1ado a la lista de documentos y cierro fichero.\n",
        "\n",
        "Resumen libro en: /home/nievesabalos/Escritorio/nlp/bookstore/DUNE 1.txt\n",
        "Leo datos y preproceso.\n",
        "A\u00f1ado a la lista de documentos y cierro fichero.\n",
        "\n",
        "Resumen libro en: /home/nievesabalos/Escritorio/nlp/bookstore/BUENOS DIAS PRINCESA.txt\n",
        "Leo datos y preproceso.\n",
        "A\u00f1ado a la lista de documentos y cierro fichero.\n",
        "\n",
        "Resumen libro en: /home/nievesabalos/Escritorio/nlp/bookstore/GENERACION DE MODELOS DE NEGOCIO.txt\n",
        "Leo datos y preproceso.\n",
        "A\u00f1ado a la lista de documentos y cierro fichero.\n",
        "\n",
        "Resumen libro en: /home/nievesabalos/Escritorio/nlp/bookstore/EL METODO DE LEAN STARTUP.txt\n",
        "Leo datos y preproceso.\n",
        "A\u00f1ado a la lista de documentos y cierro fichero.\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print documentos\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['mr mercedes es la historia de una guerra entre el bien y el mal un retrato inolvidable de la mente de un asesino obsesionado y demente justo antes del amanecer en una decadente ciudad americana cientos de parados esperan la apertura de la oficina de empleo para reclamar uno de los mil puestos de trabajo que se han anunci ado han hecho cola durante toda la noche de pronto invisible hasta que lo tienen practicamente encima un mercedes surge de la fria niebla de la madrugada su conductor atropella y aplasta a todos los que encuentra a su alcance acto seguido el coche da marcha atras y vuelve a arremeter contra ellos el asesino huye dejando atras ocho muertos y quince heridos meses despues bill hodges un policia jubilado que sigue obsesionado con este caso sin resolver recibe una carta anonima de alguien que se declara culpable de la masacre brady hartsfield vive con su madre alcoholica en la casa donde nacio disfruto tanto de aquella sensacion de muerte debajo de los neumaticos del mercedes que ahora quiere recuperarla', 'la historia de nuestros deportados sus verdugos y sus complices un libro unico cuando se cumple el setenta aniversario de la liberacion de los campos nazis tenia que intentar contar nueve mil historias una por cada uno de los espanoles y espanolas que pasaron por los campos de concentracion nazis sentia la necesidad de reflejar sus anhelos viajar con ellos en esos fatidicos trenes de la muerte acercarme a su sufrimiento en los campos a la solidaridad en que se apoyaron para tratar de sobrevivir a su alegria durante la liberacion y a su frustracion ante la imposibilidad de volver a su patria para ello visite a los pocos supervivientes que aun pueden hablar en primera persona conocerles ha sido uno de los mayores privilegios que me ha dado la vida no es un libro facil nunca pretendio serlo pero espero que resulte util ya que la historia de nuestros deportados no tiene fecha de caducidad la intolerancia el racismo el populismo las traiciones que sufrieron los pactos que hicieron sus verdugos la pasividad de los hombres buenos casi todo lo ocurrido se puede extrapolar hasta nuestros dias en este caso quizas mas que en ningun otro mirar hacia el pasado es la mejor forma de comprender el presente y de prever nuestro futuro carlos hernandez de miguel en este libro se habla de victimas y de verdugos los ultimos espanoles supervivientes de los campos de exterminio nazis nos recuerdan su sufrimiento y la forma en que perdieron a miles de companeros a manos de los siniestros miembros de las ss sus palabras nos llevan a un mundo de torturas inimaginables pero tambien de dignidad solidaridad y resistencia esta es la historia de esos hombres y mujeres que sobrevivieron o murieron entre las alambradas de mauthausen buchenwald ravensbruck o dachau y es tambien la cronica periodistica que denuncia a los politicos militares empresarios y naciones que hicieron posible que mas de nueve mil espanoles fueran deportados a los campos de la muerte', 'katnis everdeen ha sobrevivido dos veces a los juegos del hambre pero no esta a salvo la revolucion se extiende y al parecer todos han tenido algo que ver en el meticuloso plan todos excepto katniss aun asi su papel enla batalla final es el mas importante de todos katniss debe convertirse en el sinsajo en el simbolo de la rebelion a cualquier precio que empiecen los septuagesimo sextos juegos del hambre', 'dune una obra maestra unanimemente reconocida como la mejor saga de ciencia ficcion de todos los tiempos arrakis un planeta desertico donde el agua es el bien mas preciado y donde llorar a los muertos es el simbolo de maxima prodigalidad paul atreides un adolescente marcado por un destino singular dotado de extr anos poderes y abocado a convertirse en dictador mesias y martir los harkonnen personificacion de las intrigas que rodean el imperio galactico buscan obtener el control sobre arrakis para disponer de la melange preciosa especia y uno de los bienes mas codiciados del universo los fremen seres libres que han convertido el inhospito paraje de dune en su hogar y que se sienten orgullosos de su pasado y temerosos de su futuro', 'han pasado algo mas de dos anos en la vida de los chicos que formanel club de los incomprendidos las cosas han cambiado desde que uno tras otro se fueron encontrando en el camino nuevos problemas secretos amores celos sin embargo hasta el momento su amistad ha podido con todo y con todos raul se ha convertido e n un atractivo joven y en un lider nato valeria derrocha simpatia por donde pisa aunque no ha vencido del todo a su timidez eli es la que mas se ha transformado de todos y se los lleva de calle maria vigila y suena tras sus gafas de pasta de color azul bruno no consigue olvidar lo que siente y en lo mas profundo de su corazon espera ser correspondido y ester es la nuera que toda madre querria tener aunque no es tan inocente como todos piensan son seis chicos que sienten sufren aman creen rien evolucionan como otros chicos de su edad pero los seis son especiales al menos para el resto del grupo conseguiran superar todas las pruebas que se le van a presentar solo puedes averiguarlo leyendo buenos dias princesa', 'la invencion de nuevos modelos de negocio es algo paradigmatico de nuestro tiempo aun y cuando la mayoria sean poco comprensibles y dificiles de implementar generacion de modelos de negocio expone de un modo practico las innovadoras tecnicas y modelos que son usados a dia de hoy por las principales empresas del mundo tal es como 3m ericsson o deloitte y permite disenar entender y aplicar nuevos modelos de negocio asi como analizar y mejorar los ya existentes pero este no es un libro al uso esta disenado con el objetivo de ser claro sencillo y esquematico utiliza un lenguaje visual para que el lector asimile de forma rapida la teoria que lo sustenta los ejemplos se muestran de forma grafica y el contenido viene complementado con ejercicios que el lector puede utilizar cuando lo requiera mas que un libro convencional es una guia practica sobre innovacion empresarial util para visionarios y adalides de la eficacia y la mejora continua', 'el metodo lean startup supone un nuevo enfoque que se esta adoptando en todo el mundo para cambiar la forma en que las empresas crean y lanzan sus productos eric ries define una startup como una organizacion dedicada a crear algo bajo condiciones de incertidumbre extrema esto se cumple tanto para aquellas personas que trab ajan en el garaje de su casa como para un grupo de profesionales experimentados de una de las empresas queaparecen en el ranking de la revista fortune lo que todos ellos tienen en comun es la mision de traspasar la incertidumbre para encontrar el camino hacia un negocio sostenible el enfoque que el autor nos muestra en el metodo lean startup hace que las empresas sean mas eficientes en el uso del capital y que apoyen de manera mas efectiva la creatividad humana se trata de poner en marcha diversas practicas que acortan el ciclo de desarrollo del producto miden el progreso real sin recurrir a los indicadores vanidosos y ayudan a entender que es lo que realmente quieren los consumidores ademas este metodo permite a la empresa cambiar de direccion con agilidad y alterar los planes minuto a minuto en lugar de despilfarrar tiempo disenando elaborados planes de negocio el metodo lean startup ofrece a los emprendedores de empresas grandes y pequenas la mejor manera para poner a prueba de forma continua su vision para adaptarla y ajustarla antes de que sea demasiado tarde']\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "TEXT ANALYTICS"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Fichero de stopwords\n",
      "stopwordsPath = '/home/nievesabalos/Escritorio/nlp/stopwords/stop-words-spanish.txt'\n",
      "f = open(stopwordsPath, 'r')\n",
      "\n",
      "stoplist = []\n",
      "line = f.read()\n",
      "line = line + \"libro\"\n",
      "stoplist = clean(line.decode('utf-8')).split(\"\\n\") # \u00bf? problemas con gensim y tildes y e\u00f1es...\n",
      "\n",
      "print stoplist"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['y', 'o', 'que', 'del', 'de', 'el', 'la', 'lo', 'a', 'aun', 'algun', 'alguna', 'algunas', 'alguno', 'algunos', 'ambos', 'ampleamos', 'ante', 'antes', 'aquel', 'aquellas', 'aquellos', 'aqui', 'arriba', 'atras', 'bajo', 'bastante', 'bien', 'cada', 'cierta', 'ciertas', 'cierto', 'ciertos', 'como', 'con', 'conseguimos', 'conseguir', 'consigo', 'consigue', 'consiguen', 'consigues', 'cual', 'cuando', 'dentro', 'desde', 'donde', 'dos', 'ellas', 'ellos', 'empleais', 'emplean', 'emplear', 'empleas', 'empleo', 'en', 'encima', 'entonces', 'entre', 'era', 'eramos', 'eran', 'eras', 'eres', 'es', 'esta', 'este', 'estaba', 'estado', 'estais', 'estamos', 'estan', 'estoy', 'fin', 'fue', 'fueron', 'fui', 'fuimos', 'gueno', 'ha', 'han', 'hace', 'haceis', 'hacemos', 'hacen', 'hacer', 'haces', 'hago', 'incluso', 'intenta', 'intentais', 'intentamos', 'intentan', 'intentar', 'intentas', 'intento', 'ir', 'la', 'largo', 'las', 'lo', 'los', 'mientras', 'mio', 'modo', 'muchos', 'muy', 'nos', 'nosotros', 'otro', 'para', 'pero', 'podeis', 'podemos', 'poder', 'podria', 'podriais', 'podriamos', 'podrian', 'podrias', 'por', 'por que', 'porque', 'primero', 'puede', 'pueden', 'puedo', 'quien', 'sabe', 'sabeis', 'sabemos', 'saben', 'saber', 'sabes', 'ser', 'se', 'si', 'siendo', 'sin', 'sobre', 'sois', 'solamente', 'solo', 'somos', 'soy', 'su', 'sus', 'tambien', 'teneis', 'tenemos', 'tener', 'tengo', 'tiempo', 'tiene', 'tienen', 'todo', 'trabaja', 'trabajais', 'trabajamos', 'trabajan', 'trabajar', 'trabajas', 'trabajo', 'tras', 'tuyo', 'ultimo', 'un', 'una', 'unas', 'uno', 'unos', 'usa', 'usais', 'usamos', 'usan', 'usar', 'usas', 'uso', 'va', 'vais', 'valor', 'vamos', 'van', 'vaya', 'verdad', 'verdadera', 'verdadero', 'vosotras', 'vosotros', 'voy', 'yo', 'libro']\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# remove common words and tokenize\n",
      "texts = [[word for word in document.split() if word not in stoplist] for document in documentos]\n",
      "\n",
      "print(texts)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[['mr', 'mercedes', 'historia', 'guerra', 'mal', 'retrato', 'inolvidable', 'mente', 'asesino', 'obsesionado', 'demente', 'justo', 'amanecer', 'decadente', 'ciudad', 'americana', 'cientos', 'parados', 'esperan', 'apertura', 'oficina', 'reclamar', 'mil', 'puestos', 'anunci', 'ado', 'hecho', 'cola', 'durante', 'toda', 'noche', 'pronto', 'invisible', 'hasta', 'practicamente', 'mercedes', 'surge', 'fria', 'niebla', 'madrugada', 'conductor', 'atropella', 'aplasta', 'todos', 'encuentra', 'alcance', 'acto', 'seguido', 'coche', 'da', 'marcha', 'vuelve', 'arremeter', 'contra', 'asesino', 'huye', 'dejando', 'ocho', 'muertos', 'quince', 'heridos', 'meses', 'despues', 'bill', 'hodges', 'policia', 'jubilado', 'sigue', 'obsesionado', 'caso', 'resolver', 'recibe', 'carta', 'anonima', 'alguien', 'declara', 'culpable', 'masacre', 'brady', 'hartsfield', 'vive', 'madre', 'alcoholica', 'casa', 'nacio', 'disfruto', 'tanto', 'aquella', 'sensacion', 'muerte', 'debajo', 'neumaticos', 'mercedes', 'ahora', 'quiere', 'recuperarla'], ['historia', 'nuestros', 'deportados', 'verdugos', 'complices', 'unico', 'cumple', 'setenta', 'aniversario', 'liberacion', 'campos', 'nazis', 'tenia', 'contar', 'nueve', 'mil', 'historias', 'espanoles', 'espanolas', 'pasaron', 'campos', 'concentracion', 'nazis', 'sentia', 'necesidad', 'reflejar', 'anhelos', 'viajar', 'esos', 'fatidicos', 'trenes', 'muerte', 'acercarme', 'sufrimiento', 'campos', 'solidaridad', 'apoyaron', 'tratar', 'sobrevivir', 'alegria', 'durante', 'liberacion', 'frustracion', 'imposibilidad', 'volver', 'patria', 'ello', 'visite', 'pocos', 'supervivientes', 'hablar', 'primera', 'persona', 'conocerles', 'sido', 'mayores', 'privilegios', 'me', 'dado', 'vida', 'no', 'facil', 'nunca', 'pretendio', 'serlo', 'espero', 'resulte', 'util', 'ya', 'historia', 'nuestros', 'deportados', 'no', 'fecha', 'caducidad', 'intolerancia', 'racismo', 'populismo', 'traiciones', 'sufrieron', 'pactos', 'hicieron', 'verdugos', 'pasividad', 'hombres', 'buenos', 'casi', 'ocurrido', 'extrapolar', 'hasta', 'nuestros', 'dias', 'caso', 'quizas', 'mas', 'ningun', 'mirar', 'hacia', 'pasado', 'mejor', 'forma', 'comprender', 'presente', 'prever', 'nuestro', 'futuro', 'carlos', 'hernandez', 'miguel', 'habla', 'victimas', 'verdugos', 'ultimos', 'espanoles', 'supervivientes', 'campos', 'exterminio', 'nazis', 'recuerdan', 'sufrimiento', 'forma', 'perdieron', 'miles', 'companeros', 'manos', 'siniestros', 'miembros', 'ss', 'palabras', 'llevan', 'mundo', 'torturas', 'inimaginables', 'dignidad', 'solidaridad', 'resistencia', 'historia', 'esos', 'hombres', 'mujeres', 'sobrevivieron', 'murieron', 'alambradas', 'mauthausen', 'buchenwald', 'ravensbruck', 'dachau', 'cronica', 'periodistica', 'denuncia', 'politicos', 'militares', 'empresarios', 'naciones', 'hicieron', 'posible', 'mas', 'nueve', 'mil', 'espanoles', 'fueran', 'deportados', 'campos', 'muerte'], ['katnis', 'everdeen', 'sobrevivido', 'veces', 'juegos', 'hambre', 'no', 'salvo', 'revolucion', 'extiende', 'al', 'parecer', 'todos', 'tenido', 'algo', 'ver', 'meticuloso', 'plan', 'todos', 'excepto', 'katniss', 'asi', 'papel', 'enla', 'batalla', 'final', 'mas', 'importante', 'todos', 'katniss', 'debe', 'convertirse', 'sinsajo', 'simbolo', 'rebelion', 'cualquier', 'precio', 'empiecen', 'septuagesimo', 'sextos', 'juegos', 'hambre'], ['dune', 'obra', 'maestra', 'unanimemente', 'reconocida', 'mejor', 'saga', 'ciencia', 'ficcion', 'todos', 'tiempos', 'arrakis', 'planeta', 'desertico', 'agua', 'mas', 'preciado', 'llorar', 'muertos', 'simbolo', 'maxima', 'prodigalidad', 'paul', 'atreides', 'adolescente', 'marcado', 'destino', 'singular', 'dotado', 'extr', 'anos', 'poderes', 'abocado', 'convertirse', 'dictador', 'mesias', 'martir', 'harkonnen', 'personificacion', 'intrigas', 'rodean', 'imperio', 'galactico', 'buscan', 'obtener', 'control', 'arrakis', 'disponer', 'melange', 'preciosa', 'especia', 'bienes', 'mas', 'codiciados', 'universo', 'fremen', 'seres', 'libres', 'convertido', 'inhospito', 'paraje', 'dune', 'hogar', 'sienten', 'orgullosos', 'pasado', 'temerosos', 'futuro'], ['pasado', 'algo', 'mas', 'anos', 'vida', 'chicos', 'formanel', 'club', 'incomprendidos', 'cosas', 'cambiado', 'encontrando', 'camino', 'nuevos', 'problemas', 'secretos', 'amores', 'celos', 'embargo', 'hasta', 'momento', 'amistad', 'podido', 'todos', 'raul', 'convertido', 'e', 'n', 'atractivo', 'joven', 'lider', 'nato', 'valeria', 'derrocha', 'simpatia', 'pisa', 'aunque', 'no', 'vencido', 'timidez', 'eli', 'mas', 'transformado', 'todos', 'lleva', 'calle', 'maria', 'vigila', 'suena', 'gafas', 'pasta', 'color', 'azul', 'bruno', 'no', 'olvidar', 'siente', 'mas', 'profundo', 'corazon', 'espera', 'correspondido', 'ester', 'nuera', 'toda', 'madre', 'querria', 'aunque', 'no', 'tan', 'inocente', 'todos', 'piensan', 'son', 'seis', 'chicos', 'sienten', 'sufren', 'aman', 'creen', 'rien', 'evolucionan', 'otros', 'chicos', 'edad', 'seis', 'son', 'especiales', 'al', 'menos', 'resto', 'grupo', 'conseguiran', 'superar', 'todas', 'pruebas', 'le', 'presentar', 'puedes', 'averiguarlo', 'leyendo', 'buenos', 'dias', 'princesa'], ['invencion', 'nuevos', 'modelos', 'negocio', 'algo', 'paradigmatico', 'nuestro', 'mayoria', 'sean', 'poco', 'comprensibles', 'dificiles', 'implementar', 'generacion', 'modelos', 'negocio', 'expone', 'practico', 'innovadoras', 'tecnicas', 'modelos', 'son', 'usados', 'dia', 'hoy', 'principales', 'empresas', 'mundo', 'tal', '3m', 'ericsson', 'deloitte', 'permite', 'disenar', 'entender', 'aplicar', 'nuevos', 'modelos', 'negocio', 'asi', 'analizar', 'mejorar', 'ya', 'existentes', 'no', 'al', 'disenado', 'objetivo', 'claro', 'sencillo', 'esquematico', 'utiliza', 'lenguaje', 'visual', 'lector', 'asimile', 'forma', 'rapida', 'teoria', 'sustenta', 'ejemplos', 'muestran', 'forma', 'grafica', 'contenido', 'viene', 'complementado', 'ejercicios', 'lector', 'utilizar', 'requiera', 'mas', 'convencional', 'guia', 'practica', 'innovacion', 'empresarial', 'util', 'visionarios', 'adalides', 'eficacia', 'mejora', 'continua'], ['metodo', 'lean', 'startup', 'supone', 'nuevo', 'enfoque', 'adoptando', 'mundo', 'cambiar', 'forma', 'empresas', 'crean', 'lanzan', 'productos', 'eric', 'ries', 'define', 'startup', 'organizacion', 'dedicada', 'crear', 'algo', 'condiciones', 'incertidumbre', 'extrema', 'esto', 'cumple', 'tanto', 'personas', 'trab', 'ajan', 'garaje', 'casa', 'grupo', 'profesionales', 'experimentados', 'empresas', 'queaparecen', 'ranking', 'revista', 'fortune', 'todos', 'comun', 'mision', 'traspasar', 'incertidumbre', 'encontrar', 'camino', 'hacia', 'negocio', 'sostenible', 'enfoque', 'autor', 'muestra', 'metodo', 'lean', 'startup', 'empresas', 'sean', 'mas', 'eficientes', 'capital', 'apoyen', 'manera', 'mas', 'efectiva', 'creatividad', 'humana', 'trata', 'poner', 'marcha', 'diversas', 'practicas', 'acortan', 'ciclo', 'desarrollo', 'producto', 'miden', 'progreso', 'real', 'recurrir', 'indicadores', 'vanidosos', 'ayudan', 'entender', 'realmente', 'quieren', 'consumidores', 'ademas', 'metodo', 'permite', 'empresa', 'cambiar', 'direccion', 'agilidad', 'alterar', 'planes', 'minuto', 'minuto', 'lugar', 'despilfarrar', 'disenando', 'elaborados', 'planes', 'negocio', 'metodo', 'lean', 'startup', 'ofrece', 'emprendedores', 'empresas', 'grandes', 'pequenas', 'mejor', 'manera', 'poner', 'prueba', 'forma', 'continua', 'vision', 'adaptarla', 'ajustarla', 'sea', 'demasiado', 'tarde']]\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# depende, quiz\u00e1s no me interese usar esta funci\u00f3n\n",
      "\n",
      "# remove words that appear only once\n",
      "all_tokens = sum(texts, [])\n",
      "tokens_once = set(word for word in set(all_tokens) if all_tokens.count(word) == 1)\n",
      "texts2 = [[word for word in text if word not in tokens_once] for text in texts]\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print texts2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[['mercedes', 'historia', 'asesino', 'obsesionado', 'mil', 'durante', 'toda', 'hasta', 'mercedes', 'todos', 'marcha', 'asesino', 'muertos', 'obsesionado', 'caso', 'madre', 'casa', 'tanto', 'muerte', 'mercedes'], ['historia', 'nuestros', 'deportados', 'verdugos', 'cumple', 'liberacion', 'campos', 'nazis', 'nueve', 'mil', 'espanoles', 'campos', 'nazis', 'esos', 'muerte', 'sufrimiento', 'campos', 'solidaridad', 'durante', 'liberacion', 'supervivientes', 'vida', 'no', 'util', 'ya', 'historia', 'nuestros', 'deportados', 'no', 'hicieron', 'verdugos', 'hombres', 'buenos', 'hasta', 'nuestros', 'dias', 'caso', 'mas', 'hacia', 'pasado', 'mejor', 'forma', 'nuestro', 'futuro', 'verdugos', 'espanoles', 'supervivientes', 'campos', 'nazis', 'sufrimiento', 'forma', 'mundo', 'solidaridad', 'historia', 'esos', 'hombres', 'hicieron', 'mas', 'nueve', 'mil', 'espanoles', 'deportados', 'campos', 'muerte'], ['juegos', 'hambre', 'no', 'al', 'todos', 'algo', 'todos', 'katniss', 'asi', 'mas', 'todos', 'katniss', 'convertirse', 'simbolo', 'juegos', 'hambre'], ['dune', 'mejor', 'todos', 'arrakis', 'mas', 'muertos', 'simbolo', 'anos', 'convertirse', 'arrakis', 'mas', 'convertido', 'dune', 'sienten', 'pasado', 'futuro'], ['pasado', 'algo', 'mas', 'anos', 'vida', 'chicos', 'camino', 'nuevos', 'hasta', 'todos', 'convertido', 'aunque', 'no', 'mas', 'todos', 'no', 'mas', 'toda', 'madre', 'aunque', 'no', 'todos', 'son', 'seis', 'chicos', 'sienten', 'chicos', 'seis', 'son', 'al', 'grupo', 'buenos', 'dias'], ['nuevos', 'modelos', 'negocio', 'algo', 'nuestro', 'sean', 'modelos', 'negocio', 'modelos', 'son', 'empresas', 'mundo', 'permite', 'entender', 'nuevos', 'modelos', 'negocio', 'asi', 'ya', 'no', 'al', 'lector', 'forma', 'forma', 'lector', 'mas', 'util', 'continua'], ['metodo', 'lean', 'startup', 'enfoque', 'mundo', 'cambiar', 'forma', 'empresas', 'startup', 'algo', 'incertidumbre', 'cumple', 'tanto', 'casa', 'grupo', 'empresas', 'todos', 'incertidumbre', 'camino', 'hacia', 'negocio', 'enfoque', 'metodo', 'lean', 'startup', 'empresas', 'sean', 'mas', 'manera', 'mas', 'poner', 'marcha', 'entender', 'metodo', 'permite', 'cambiar', 'planes', 'minuto', 'minuto', 'planes', 'negocio', 'metodo', 'lean', 'startup', 'empresas', 'mejor', 'manera', 'poner', 'forma', 'continua']]\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To convert documents to vectors, we\u2019ll use a document representation called bag-of-words"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dictionary = corpora.Dictionary(texts)\n",
      "dictionary.save('/home/nievesabalos/Escritorio/nlp/books/books.dict') # store the dictionary, for future reference\n",
      "print(dictionary)\n",
      "\n",
      "# This sweeps across the texts, collecting word counts and relevant statistics. In the end,\n",
      "# we see there are twelve distinct words in the processed corpus, which means each document will be represented by \n",
      "# 255 numbers (ie., by a 255-D vector). "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Dictionary(538 unique tokens: [u'galactico', u'indicadores', u'dejando', u'unico', u'tratar']...)\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      " To see the mapping between words and their ids:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(dictionary.token2id)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{u'galactico': 277, u'indicadores': 497, u'dejando': 32, u'unico': 212, u'tratar': 209, u'sufren': 381, u'ciudad': 22, u'lider': 350, u'quizas': 187, u'resulte': 193, u'habla': 133, u'querria': 371, u'ver': 254, u'presente': 182, u'katnis': 237, u'viajar': 215, u'nuestros': 165, u'empresas': 410, u'caducidad': 100, u'alcoholica': 4, u'supone': 531, u'hodges': 46, u'util': 213, u'cumple': 111, u'sufrimiento': 204, u'sobrevivido': 251, u'marcha': 55, u'solidaridad': 201, u'edad': 334, u'deportados': 115, u'ejemplos': 407, u'recuerdan': 190, u'sextos': 248, u'mirar': 155, u'dia': 402, u'menos': 353, u'entender': 411, u'meses': 59, u'militares': 154, u'katniss': 238, u'orgullosos': 293, u'esos': 120, u'ocho': 69, u'revista': 526, u'corazon': 328, u'arremeter': 13, u'mejorar': 428, u'vigila': 389, u'ayudan': 463, u'inolvidable': 48, u'capital': 465, u'ejercicios': 408, u'empresa': 485, u'dias': 116, u'nazis': 160, u'cambiar': 464, u'fremen': 276, u'timidez': 384, u'principales': 438, u'eficacia': 406, u'poderes': 298, u'asimile': 394, u'dedicada': 473, u'aquella': 12, u'princesa': 366, u'aunque': 316, u'producto': 515, u'adolescente': 256, u'precio': 243, u'grandes': 494, u'profundo': 368, u'resto': 373, u'ultimos': 211, u'ravensbruck': 189, u'claro': 395, u'acortan': 453, u'palabras': 170, u'realmente': 524, u'raul': 372, u'hablar': 134, u'otros': 360, u'chicos': 324, u'mejora': 427, u'conocerles': 108, u'jubilado': 50, u'objetivo': 432, u'podido': 364, u'fortune': 492, u'aplicar': 393, u'todas': 385, u'inhospito': 281, u'apertura': 10, u'ciencia': 263, u'conductor': 25, u'desertico': 267, u'victimas': 216, u'preciosa': 300, u'ocurrido': 168, u'espero': 123, u'veces': 253, u'condiciones': 468, u'espera': 339, u'empiecen': 228, u'me': 149, u'enfoque': 487, u'permite': 434, u'mision': 505, u'mr': 61, u'problemas': 367, u'control': 265, u'ranking': 522, u'tecnicas': 445, u'azul': 318, u'tal': 444, u'tan': 383, u'practicas': 514, u'prueba': 519, u'incomprendidos': 345, u'utiliza': 448, u'amistad': 313, u'hartsfield': 41, u'mayores': 148, u'oficina': 70, u'obsesionado': 68, u'buenos': 99, u'acto': 0, u'lenguaje': 425, u'hoy': 419, u'mas': 146, u'amanecer': 6, u'mauthausen': 147, u'siniestros': 198, u'agua': 257, u'cambiado': 321, u'mal': 54, u'arrakis': 259, u'abocado': 255, u'organizacion': 509, u'secretos': 375, u'adalides': 391, u'muertos': 63, u'brady': 17, u'ss': 202, u'disponer': 270, u'hasta': 42, u'primera': 185, u'sentia': 194, u'crean': 470, u'concentracion': 107, u'extrapolar': 125, u'minuto': 504, u'manera': 501, u'atropella': 15, u'papel': 240, u'hacia': 135, u'cola': 24, u'forma': 129, u'le': 348, u'singular': 307, u'pronto': 74, u'buscan': 262, u'demente': 33, u'madre': 52, u'requiera': 440, u'generacion': 416, u'personas': 511, u'tiempos': 309, u'liberacion': 143, u'inimaginables': 141, u'practico': 437, u'suena': 380, u'maestra': 285, u'ya': 220, u'muestran': 430, u'dificiles': 403, u'camino': 322, u'practica': 436, u'imperio': 280, u'denuncia': 114, u'simpatia': 378, u'paradigmatico': 433, u'importante': 235, u'extr': 274, u'trab': 533, u'anunci': 9, u'sido': 197, u'carlos': 102, u'setenta': 196, u'nacio': 64, u'toda': 88, u'pretendio': 183, u'hogar': 279, u'viene': 450, u'nunca': 167, u'tenido': 252, u'poco': 435, u'alambradas': 93, u'deloitte': 401, u'quince': 77, u'ajan': 458, u'diversas': 480, u'dune': 272, u'declara': 31, u'formanel': 342, u'masacre': 56, u'derrocha': 332, u'resistencia': 192, u'obra': 291, u'asi': 223, u'pasado': 171, u'pasaron': 172, u'miden': 503, u'personificacion': 296, u'ajustarla': 459, u'alterar': 460, u'cronica': 110, u'decadente': 30, u'disfruto': 35, u'gafas': 343, u'pactos': 169, u'prodigalidad': 301, u'creatividad': 472, u'americana': 7, u'innovacion': 421, u'everdeen': 230, u'tenia': 206, u'sienten': 306, u'facil': 126, u'negocio': 431, u'existentes': 414, u'contra': 26, u'excepto': 231, u'anhelos': 95, u'historias': 138, u'final': 233, u'invencion': 423, u'intolerancia': 142, u'comprender': 106, u'sobrevivir': 200, u'aniversario': 96, u'dotado': 271, u'apoyaron': 97, u'metodo': 502, u'llevan': 144, u'visionarios': 451, u'debajo': 29, u'imposibilidad': 140, u'futuro': 132, u'reclamar': 79, u'esto': 489, u'frustracion': 130, u'dachau': 112, u'politicos': 179, u'poner': 513, u'mil': 60, u'profesionales': 517, u'despilfarrar': 477, u'transformado': 386, u'lugar': 500, u'esquematico': 413, u'manos': 145, u'nuevos': 358, u'aman': 312, u'perdieron': 175, u'plan': 242, u'cualquier': 226, u'fria': 39, u'maria': 352, u'agilidad': 457, u'reflejar': 191, u'sufrieron': 203, u'juegos': 236, u'pruebas': 369, u'martir': 287, u'buchenwald': 98, u'traiciones': 208, u'saga': 304, u'superar': 382, u'olvidar': 359, u'sobrevivieron': 199, u'madrugada': 53, u'quieren': 521, u'fecha': 128, u'unanimemente': 310, u'sensacion': 84, u'atractivo': 315, u'conseguiran': 327, u'bienes': 261, u'grafica': 417, u'3m': 390, u'dignidad': 117, u'da': 28, u'autor': 462, u'joven': 347, u'puestos': 75, u'ademas': 455, u'especia': 273, u'piensan': 362, u'miles': 153, u'torturas': 207, u'mercedes': 58, u'vision': 537, u'comprensibles': 397, u'convertido': 266, u'guerra': 40, u'startup': 530, u'codiciados': 264, u'sean': 441, u'sea': 528, u'contar': 109, u'culpable': 27, u'mesias': 290, u'humana': 495, u'hambre': 234, u'contenido': 398, u'pasividad': 173, u'pisa': 363, u'periodistica': 176, u'destino': 268, u'bruno': 319, u'llorar': 284, u'sustenta': 443, u'progreso': 518, u'alguien': 5, u'ningun': 162, u'anonima': 8, u'murieron': 158, u'debe': 227, u'planes': 512, u'miembros': 151, u'trenes': 210, u'atreides': 260, u'apoyen': 461, u'convertirse': 225, u'invisible': 49, u'adoptando': 456, u'seguido': 83, u'ofrece': 508, u'ahora': 2, u'anos': 258, u'utilizar': 449, u'vanidosos': 536, u'disenado': 404, u'racismo': 188, u'vida': 217, u'color': 326, u'acercarme': 92, u'parecer': 241, u'durante': 36, u'batalla': 224, u'empresarial': 409, u'intrigas': 282, u'guia': 418, u'extrema': 491, u'alcance': 3, u'asesino': 14, u'experimentados': 490, u'preciado': 299, u'hernandez': 136, u'rodean': 303, u'recibe': 78, u'demasiado': 475, u'coche': 23, u'recurrir': 525, u'puedes': 370, u'marcado': 286, u'libres': 283, u'casa': 19, u'convencional': 400, u'caso': 20, u'bill': 16, u'casi': 103, u'n': 355, u'encontrar': 486, u'simbolo': 249, u'analizar': 392, u'serlo': 195, u'despues': 34, u'celos': 323, u'hecho': 43, u'neumaticos': 65, u'innovadoras': 422, u'revolucion': 245, u'espanolas': 121, u'extiende': 232, u'efectiva': 481, u'ester': 340, u'encontrando': 337, u'todos': 89, u'adaptarla': 454, u'persona': 177, u'ello': 118, u'mujeres': 156, u'averiguarlo': 317, u'fatidicos': 127, u'nuera': 357, u'aplasta': 11, u'muestra': 506, u'sigue': 85, u'productos': 516, u'vuelve': 91, u'valeria': 387, u'dado': 113, u'paraje': 294, u'no': 163, u'sencillo': 442, u'campos': 101, u'huye': 47, u'maxima': 288, u'salvo': 246, u'garaje': 493, u'ficcion': 275, u'patria': 174, u'momento': 354, u'recuperarla': 80, u'paul': 295, u'queaparecen': 520, u'supervivientes': 205, u'nuestro': 164, u'ciclo': 466, u'eli': 335, u'quiere': 76, u'alegria': 94, u'nato': 356, u'ado': 1, u'evolucionan': 341, u'real': 523, u'historia': 45, u'seres': 305, u'volver': 219, u'resolver': 81, u'tanto': 87, u'expone': 415, u'desarrollo': 476, u'sinsajo': 250, u'verdugos': 214, u'policia': 72, u'cosas': 330, u'complementado': 396, u'creen': 331, u'retrato': 82, u'amores': 314, u'presentar': 365, u'disenar': 405, u'necesidad': 161, u'teoria': 446, u'rien': 374, u'espanoles': 122, u'disenando': 479, u'enla': 229, u'hombres': 139, u'lean': 499, u'niebla': 66, u'elaborados': 483, u'melange': 289, u'carta': 18, u'ries': 527, u'pequenas': 510, u'mayoria': 426, u'complices': 105, u'consumidores': 469, u'continua': 399, u'nuevo': 507, u'pasta': 361, u'nueve': 166, u'universo': 311, u'esperan': 38, u'justo': 51, u'lector': 424, u'surge': 86, u'correspondido': 329, u'hicieron': 137, u'algo': 222, u'trata': 535, u'encuentra': 37, u'incertidumbre': 496, u'obtener': 292, u'son': 379, u'sostenible': 529, u'leyendo': 349, u'exterminio': 124, u'usados': 447, u'dictador': 269, u'pocos': 178, u'eficientes': 482, u'naciones': 159, u'direccion': 478, u'lanzan': 498, u'muerte': 62, u'companeros': 104, u'meticuloso': 239, u'mente': 57, u'populismo': 180, u'embargo': 336, u'temerosos': 308, u'vive': 90, u'prever': 184, u'fueran': 131, u'miguel': 152, u'septuagesimo': 247, u'harkonnen': 278, u'define': 474, u'crear': 471, u'modelos': 429, u'vencido': 388, u'planeta': 297, u'lleva': 351, u'especiales': 338, u'al': 221, u'mundo': 157, u'reconocida': 302, u'implementar': 420, u'rapida': 439, u'mejor': 150, u'ericsson': 412, u'eric': 488, u'tarde': 532, u'emprendedores': 484, u'traspasar': 534, u'empresarios': 119, u'parados': 71, u'privilegios': 186, u'club': 325, u'noche': 67, u'rebelion': 244, u'inocente': 346, u'heridos': 44, u'siente': 377, u'visite': 218, u'grupo': 344, u'seis': 376, u'practicamente': 73, u'e': 333, u'posible': 181, u'comun': 467, u'cientos': 21, u'visual': 452, u'calle': 320}\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To actually convert tokenized documents to vectors:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "new_doc = \"Los juegos del hambre 2: en llamas. Katniss Everdeen ha sobrevivido a Los juegos del hambre.\"\n",
      "new_vec = dictionary.doc2bow(new_doc.lower().split())\n",
      "print(new_vec) # the word \"interaction\" does not appear in the dictionary and is ignored\n",
      "\n",
      "\n",
      "# The function doc2bow() simply counts the number of occurences of each distinct word, converts the word to its integer word\n",
      "# id and returns the result as a sparse vector. The sparse vector [(230, 1), (234, 1), (236, 2), (238, 1), (251, 1)]\n",
      "# for example: in the document mew_doc, the words u'everdeen (id 230) and u'hambre (id 234) appear once; u'juegos (id 236) \n",
      "# twice and the other words appear (implicitly) zero times."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(230, 1), (234, 1), (236, 2), (238, 1), (251, 1)]\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "One of the more notable file formats is the Market Matrix format. To save a corpus in the Matrix Market format:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "corpus = [dictionary.doc2bow(text) for text in texts]\n",
      "corpora.MmCorpus.serialize('/home/nievesabalos/Escritorio/nlp/books/books.mm', corpus) # store to disk, for later use\n",
      "#print(corpus)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Para Corpus Streaming \u2013 One Document at a Time (ver http://radimrehurek.com/gensim/tut1.html)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Conversely, to load a corpus iterator from a Matrix Market file:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "corpus = corpora.MmCorpus('/home/nievesabalos/Escritorio/nlp/books/books.mm')\n",
      "#print(corpus)\n",
      "# one way of printing a corpus: load it entirely into memory\n",
      "#print(list(corpus)) # calling list() will convert any sequence to a plain Python list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Topics and transformations"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "tf-idf"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The transformations are standard Python objects, typically initialized by means of a training corpus:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# corpus is bow_corpus\n",
      "tfidf = models.TfidfModel(corpus) # step 1 -- initialize a model"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We used our old corpus from tutorial 1 to initialize (train) the transformation model. Different transformations may require different initialization parameters; in case of TfIdf, the \u201ctraining\u201d consists simply of going through the supplied corpus once and computing document frequencies of all its features. Training other models, such as Latent Semantic Analysis or Latent Dirichlet Allocation, is much more involved and, consequently, takes much more time."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Transformations always convert between two specific vector spaces. The same vector space (= the same set of feature ids) must be used for training as well as for subsequent vector transformations. Failure to use the same input feature space, such as applying a different string preprocessing, using different feature ids, or using bag-of-words input vectors where TfIdf vectors are expected, will result in feature mismatch during transformation calls and consequently in either garbage output and/or runtime exceptions."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "From now on, tfidf is treated as a read-only object that can be used to convert any vector from the old representation (bag-of-words integer counts) to the new representation (TfIdf real-valued weights):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# es el new_vec de arriba...\n",
      "doc_bow = [(230, 1), (234, 1), (236, 2), (238, 1), (251, 1)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(tfidf[doc_bow]) # step 2 -- use the model to transform vectors"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(230, 0.35355339059327373), (234, 0.35355339059327373), (236, 0.7071067811865475), (238, 0.35355339059327373), (251, 0.35355339059327373)]\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Or to apply a transformation to a whole corpus:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "corpus_tfidf = tfidf[corpus]\n",
      "#for doc in corpus_tfidf:\n",
      "#    print(doc)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tfidf.save('/home/nievesabalos/Escritorio/nlp/books/booksModel.tfidf') \n",
      "#tfidf = models.TfidfModel.load('/....tfidf')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "LSI"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lsi = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=4) # initialize an LSI transformation\n",
      "corpus_lsi = lsi[corpus_tfidf] # create a double wrapper over the original corpus: bow->tfidf->fold-in-lsi"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 102
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here we transformed our Tf-Idf corpus via Latent Semantic Indexing into a latent 2-D space (2-D because we set num_topics=2). Now you\u2019re probably wondering: what do these two latent dimensions stand for? Let\u2019s inspect with models.LsiModel.print_topics():"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lsi.print_topics(4)\n",
      "\n",
      "# topic 0 = modelos negocio startup metodo empresas lector lean chicos campos forma\n",
      "# topic 1 = modelos startup metodo arrakis dune negocio empresas lean\" juegos katniss \n",
      "# topic 2 = mercedes campos hambre juegos katniss asesino obsesionado historia nazis deportados \n",
      "# topic 3 = hambre katniss juegos chicos aunque seis ver veces tenido batalla "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 103,
       "text": [
        "[u'0.236*\"modelos\" + 0.164*\"negocio\" + 0.157*\"startup\" + 0.157*\"metodo\" + 0.139*\"empresas\" + 0.118*\"lector\" + 0.118*\"lean\" + 0.113*\"chicos\" + 0.113*\"campos\" + 0.105*\"forma\"',\n",
        " u'0.165*\"modelos\" + 0.142*\"startup\" + 0.142*\"metodo\" + -0.133*\"arrakis\" + -0.133*\"dune\" + 0.125*\"negocio\" + 0.118*\"empresas\" + 0.107*\"lean\" + -0.101*\"juegos\" + -0.101*\"katniss\"',\n",
        " u'0.180*\"mercedes\" + 0.172*\"campos\" + -0.155*\"katniss\" + -0.155*\"hambre\" + -0.155*\"juegos\" + 0.120*\"asesino\" + 0.120*\"obsesionado\" + 0.105*\"historia\" + 0.103*\"deportados\" + 0.103*\"espanoles\"',\n",
        " u'0.227*\"hambre\" + 0.227*\"katniss\" + 0.227*\"juegos\" + -0.186*\"chicos\" + -0.124*\"aunque\" + -0.124*\"seis\" + 0.114*\"ver\" + 0.114*\"veces\" + 0.114*\"tenido\" + 0.114*\"batalla\"']"
       ]
      }
     ],
     "prompt_number": 103
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It appears that according to LSI, \u201ccampos\u201d, \u201cmercedes\u201d and \u201ckatniss\u201d are all related words (and contribute the most to the direction of the first topic), while the second topic practically concerns itself with all the other words. As expected, the first five documents are more strongly related to the second topic while the remaining four documents to the first topic:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for doc in corpus_lsi: # both bow->tfidf and tfidf->lsi transformations are actually executed here, on the fly\n",
      "    print(doc)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(0, 0.24996153935122031), (1, -0.31874333415388773), (2, 0.60275509907410663), (3, 0.27477674754551851)]\n",
        "[(0, 0.36073345338639085), (1, -0.22610151354670793), (2, 0.51309608012470009), (3, 0.071585462584535769)]\n",
        "[(0, 0.22545065212674897), (1, -0.32911180743438434), (2, -0.4967591151671108), (3, 0.70573845365899668)]\n",
        "[(0, 0.20599900777690555), (1, -0.54403197387054425), (2, -0.31603869253640565), (3, -0.21180637236547217)]\n",
        "[(0, 0.40128512653995396), (1, -0.32565171055362258), (2, -0.13575066657091764), (3, -0.5963004250895606)]\n",
        "[(0, 0.59256976489189639), (1, 0.39207884821105804), (2, -0.1535701049546295), (3, -0.013345325007030111)]\n",
        "[(0, 0.53591431160669445), (1, 0.45874794595886398), (2, -0.024598084221932218), (3, 0.069433386735172575)]\n"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Aqu\u00ed, cada fila es un resumen de un libro y cada columna hace referencia a uno de los t\u00f3picos indicados arriba..\n",
      "\n",
      "1 /bookstore/MR MERCEDES.txt\n",
      "\n",
      "2 /bookstore/LOS \u00daLTIMOS ESPA\u00d1OLES DE MAUTHAUSEN.txt\n",
      "\n",
      "3 /bookstore/JUEGOS DEL HAMBRE 3 SINSAJO.txt\n",
      "\n",
      "4 /bookstore/DUNE 1.txt\n",
      "\n",
      "5 /bookstore/BUENOS DIAS PRINCESA.txt\n",
      "\n",
      "6 /bookstore/GENERACION DE MODELOS DE NEGOCIO.txt\n",
      "\n",
      "7 /bookstore/EL METODO DE LEAN STARTUP.txt"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Model persistency is achieved with the save() and load() functions:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lsi.save('/home/nievesabalos/Escritorio/nlp/books/booksModel.lsi') # same for tfidf, lda, ...\n",
      "#lsi = models.LsiModel.load('/.....lsi')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "LDA"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lda = models.LdaModel(corpus, id2word=dictionary, num_topics=7) # inicializo el modelo"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
       ]
      }
     ],
     "prompt_number": 87
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(lda[doc_bow]) # step 2 -- use the model to transform vectors"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(0, 0.020408269251428988), (1, 0.020408288712100753), (2, 0.02040822024348829), (3, 0.020408257977247497), (4, 0.020408234060885103), (5, 0.020409617987568546), (6, 0.87754911176728079)]\n"
       ]
      }
     ],
     "prompt_number": 88
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "corpus_lda = lda[corpus]\n",
      "lda.print_topics(7)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 90,
       "text": [
        "[u'0.006*no + 0.005*mercedes + 0.005*mas + 0.005*forma + 0.005*campos + 0.005*historia + 0.005*todos + 0.004*modelos + 0.004*muerte + 0.004*obsesionado',\n",
        " u'0.008*startup + 0.006*mas + 0.006*empresas + 0.006*metodo + 0.005*negocio + 0.005*forma + 0.005*incertidumbre + 0.004*enfoque + 0.004*lean + 0.004*planes',\n",
        " u'0.011*mas + 0.011*campos + 0.008*no + 0.008*historia + 0.008*mercedes + 0.007*hasta + 0.007*verdugos + 0.007*todos + 0.007*nazis + 0.007*muerte',\n",
        " u'0.010*modelos + 0.009*mas + 0.008*todos + 0.008*no + 0.007*nuevos + 0.006*son + 0.006*chicos + 0.006*negocio + 0.006*seis + 0.005*algo',\n",
        " u'0.011*mas + 0.007*forma + 0.007*campos + 0.006*metodo + 0.006*historia + 0.006*deportados + 0.006*mejor + 0.005*espanoles + 0.005*todos + 0.005*empresas',\n",
        " u'0.014*negocio + 0.012*modelos + 0.011*forma + 0.009*empresas + 0.008*mas + 0.007*lector + 0.007*nuevos + 0.006*no + 0.006*mundo + 0.006*algo',\n",
        " u'0.020*todos + 0.013*mas + 0.009*juegos + 0.008*hambre + 0.008*katniss + 0.008*empresas + 0.008*metodo + 0.008*no + 0.008*algo + 0.008*startup']"
       ]
      }
     ],
     "prompt_number": 90
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# topic 1 = modelos negocio startup metodo empresas lector lean chicos campos forma\n",
      "# topic 2 = modelos startup metodo arrakis dune negocio empresas lean\" juegos katniss \n",
      "# topic 3 = mercedes campos hambre juegos katniss asesino obsesionado historia nazis deportados \n",
      "# topic 4 = hambre katniss juegos chicos aunque seis ver veces tenido batalla "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for doc in corpus_lda:\n",
      "    print(doc)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(2, 0.9911573627403365)]\n",
        "[(2, 0.99480009641924128)]\n",
        "[(6, 0.98006154888517061)]\n",
        "[(6, 0.98755903297041292)]\n",
        "[(2, 0.72394990599301257), (3, 0.26924014753573977)]\n",
        "[(5, 0.98978776213924302)]\n",
        "[(6, 0.99318960579767834)]\n"
       ]
      }
     ],
     "prompt_number": 91
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lda.save('/home/nievesabalos/Escritorio/nlp/books/booksModel.lda') # same for tfidf, lda, ...\n",
      "#lda = models.LdaModel.load('/.....lda')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 92
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Conclusi\u00f3n:** creo que me faltan datos y tunear LDA para el n\u00famero de topics"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Transformaci\u00f3n: de LSI al modelo word2vec"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "topics_lsi = [u'0.236*\"modelos\" + 0.164*\"negocio\" + 0.157*\"startup\" + 0.157*\"metodo\" + 0.139*\"empresas\" + 0.118*\"lector\" + 0.118*\"lean\" + 0.113*\"chicos\" + 0.113*\"campos\" + 0.105*\"forma\"',\n",
      " u'0.165*\"modelos\" + 0.142*\"startup\" + 0.142*\"metodo\" + -0.133*\"arrakis\" + -0.133*\"dune\" + 0.125*\"negocio\" + 0.118*\"empresas\" + 0.107*\"lean\" + -0.101*\"juegos\" + -0.101*\"katniss\"',\n",
      " u'0.180*\"mercedes\" + 0.172*\"campos\" + -0.155*\"hambre\" + -0.155*\"juegos\" + -0.155*\"katniss\" + 0.120*\"asesino\" + 0.120*\"obsesionado\" + 0.105*\"historia\" + 0.103*\"nazis\" + 0.103*\"deportados\"',\n",
      " u'0.227*\"hambre\" + 0.227*\"katniss\" + 0.227*\"juegos\" + -0.186*\"chicos\" + -0.124*\"aunque\" + -0.124*\"seis\" + 0.114*\"ver\" + 0.114*\"veces\" + 0.114*\"tenido\" + 0.114*\"batalla\"']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 149
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "palabrasTopic=[]\n",
      "for topic in topics_lsi:\n",
      "    palabrasTopic.append(topic.split(\"\\\"\"))\n",
      "\n",
      "print palabrasTopic[:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[u'0.236*', u'modelos', u' + 0.164*', u'negocio', u' + 0.157*', u'startup', u' + 0.157*', u'metodo', u' + 0.139*', u'empresas', u' + 0.118*', u'lector', u' + 0.118*', u'lean', u' + 0.113*', u'chicos', u' + 0.113*', u'campos', u' + 0.105*', u'forma', u''], [u'0.165*', u'modelos', u' + 0.142*', u'startup', u' + 0.142*', u'metodo', u' + -0.133*', u'arrakis', u' + -0.133*', u'dune', u' + 0.125*', u'negocio', u' + 0.118*', u'empresas', u' + 0.107*', u'lean', u' + -0.101*', u'juegos', u' + -0.101*', u'katniss', u''], [u'0.180*', u'mercedes', u' + 0.172*', u'campos', u' + -0.155*', u'hambre', u' + -0.155*', u'juegos', u' + -0.155*', u'katniss', u' + 0.120*', u'asesino', u' + 0.120*', u'obsesionado', u' + 0.105*', u'historia', u' + 0.103*', u'nazis', u' + 0.103*', u'deportados', u''], [u'0.227*', u'hambre', u' + 0.227*', u'katniss', u' + 0.227*', u'juegos', u' + -0.186*', u'chicos', u' + -0.124*', u'aunque', u' + -0.124*', u'seis', u' + 0.114*', u'ver', u' + 0.114*', u'veces', u' + 0.114*', u'tenido', u' + 0.114*', u'batalla', u'']]\n"
       ]
      }
     ],
     "prompt_number": 150
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 151
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      " model.most_similar(\"start\", topn=3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 160,
       "text": [
        "[('number', 0.790533185005188),\n",
        " ('sphere', 0.7902851104736328),\n",
        " ('prove', 0.7898560166358948)]"
       ]
      }
     ],
     "prompt_number": 160
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "conjuntoTemas=[]\n",
      "palabrasTemas=[]\n",
      "palabrasTemasProb=[]\n",
      "for topic in palabrasTopic:\n",
      "    tema = []\n",
      "    palabras = []\n",
      "    palabrasProb = []\n",
      "    prob = []\n",
      "    cont = 0\n",
      "    for word in topic:\n",
      "        cont = cont + 1\n",
      "        if cont % 2 == 1: #impares -- probabilidad (ojo con el signo!)\n",
      "            print word\n",
      "            probabilidad = clean(word)\n",
      "            if len(probabilidad) > 1:\n",
      "                numero = probabilidad.split(\" \")\n",
      "                prob.append(float(numero[1])/1000)\n",
      "        else: #pares\n",
      "            try:\n",
      "                #print \"Similares a \" + clean(word) \n",
      "                #print model.most_similar(word, topn=3)\n",
      "                palabras.append(word)\n",
      "                indice = int(cont//2)\n",
      "                probabilidadAnterior = prob[indice-1]\n",
      "                tema.append([(word,probabilidadAnterior), model.most_similar(word, topn=3)])\n",
      "                if probabilidadAnterior > 0.12:\n",
      "                    palabrasProb.append(word)\n",
      "            except KeyError, e:\n",
      "                palabras.remove(word)\n",
      "                print clean(word) + \" no est\u00e1 en el modelo word2vec.\"\n",
      "    conjuntoTemas.append(tema)\n",
      "    palabrasTemas.append(palabras)\n",
      "    palabrasTemasProb.append(palabrasProb)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.236*\n",
        " + 0.164*\n",
        " + 0.157*"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "startup no est\u00e1 en el modelo word2vec.\n",
        " + 0.157*\n",
        " + 0.139*\n",
        " + 0.118*"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " + 0.118*\n",
        " + 0.113*"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " + 0.113*\n",
        " + 0.105*"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "0.165*\n",
        " + 0.142*"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "startup no est\u00e1 en el modelo word2vec.\n",
        " + 0.142*\n",
        " + -0.133*\n",
        " + -0.133*"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " + 0.125*\n",
        " + 0.118*"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " + 0.107*\n",
        " + -0.101*"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " + -0.101*\n",
        "katniss no est\u00e1 en el modelo word2vec.\n",
        "\n",
        "0.180*\n",
        " + 0.172*"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " + -0.155*\n",
        " + -0.155*"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " + -0.155*\n",
        "katniss no est\u00e1 en el modelo word2vec.\n",
        " + 0.120*\n",
        " + 0.120*"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " + 0.105*\n",
        " + 0.103*"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " + 0.103*\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.227*\n",
        " + 0.227*\n",
        "katniss no est\u00e1 en el modelo word2vec.\n",
        " + 0.227*\n",
        " + -0.186*"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " + -0.124*\n",
        " + -0.124*"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " + 0.114*\n",
        " + 0.114*"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " + 0.114*\n",
        " + 0.114*"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 153
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"\\n TEMAS (palabras + entorno): \" \n",
      "for temas in conjuntoTemas:\n",
      "    print temas\n",
      "\n",
      "for palabras in palabrasTemas:\n",
      "    print \"\\nPalabras del topic = \" + ' '.join(palabras)\n",
      "    print \"no encaja... \"\n",
      "    palabraFuera = model.doesnt_match(palabras)\n",
      "    palabras.remove(palabraFuera)\n",
      "    print palabraFuera"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " TEMAS (palabras + entorno): \n",
        "[[(u'modelos', 0.236), [('disenos', 0.8510348796844482), ('prototipos', 0.7868496179580688), ('desarrollos', 0.7675785422325134)]], [(u'negocio', 0.164), [('monopolio', 0.6538001298904419), ('emprendimiento', 0.6267527341842651), ('mercado', 0.6253635883331299)]], [(u'metodo', 0.157), [('algoritmo', 0.7771655917167664), ('mecanismo', 0.7587835192680359), ('procedimiento', 0.7567076683044434)]], [(u'empresas', 0.139), [('companias', 0.842136025428772), ('transnacionales', 0.8163816928863525), ('pymes', 0.816049337387085)]], [(u'lector', 0.118), [('espectador', 0.7354000806808472), ('usuario', 0.6746799945831299), ('mensaje', 0.6587505340576172)]], [(u'lean', 0.118), [('deshannon', 0.6859663724899292), ('leadbelly', 0.6816211938858032), ('backwards', 0.6793063879013062)]], [(u'chicos', 0.113), [('jovenes', 0.7667895555496216), ('ninos', 0.7601310014724731), ('muchachos', 0.7577528953552246)]], [(u'campos', 0.113), [('ingenios', 0.5980852246284485), ('terrenos', 0.5884257555007935), ('monteros', 0.5731548070907593)]], [(u'forma', 0.105), [('manera', 0.67906653881073), ('lazada', 0.6144704222679138), ('estructura', 0.6122794151306152)]]]\n",
        "[[(u'modelos', 0.165), [('disenos', 0.8510348796844482), ('prototipos', 0.7868496179580688), ('desarrollos', 0.7675785422325134)]], [(u'metodo', 0.142), [('algoritmo', 0.7771655917167664), ('mecanismo', 0.7587835192680359), ('procedimiento', 0.7567076683044434)]], [(u'arrakis', 0.133), [('corrin', 0.6436410546302795), ('abulurd', 0.598179817199707), ('feyd', 0.5830298066139221)]], [(u'dune', 0.133), [('muad', 0.684756875038147), ('fille', 0.6455883979797363), ('hasegawa', 0.6253353953361511)]], [(u'negocio', 0.125), [('monopolio', 0.6538001298904419), ('emprendimiento', 0.6267527341842651), ('mercado', 0.6253635883331299)]], [(u'empresas', 0.118), [('companias', 0.842136025428772), ('transnacionales', 0.8163816928863525), ('pymes', 0.816049337387085)]], [(u'lean', 0.107), [('deshannon', 0.6859663724899292), ('leadbelly', 0.6816211938858032), ('backwards', 0.6793063879013062)]], [(u'juegos', 0.101), [('olimpicos', 0.7551369071006775), ('medallistas', 0.7083016633987427), ('istmicos', 0.7047864198684692)]]]\n",
        "[[(u'mercedes', 0.18), [('bibiana', 0.6951180100440979), ('elisa', 0.6851274967193604), ('furiase', 0.6849612593650818)]], [(u'campos', 0.172), [('ingenios', 0.5980852246284485), ('terrenos', 0.5884257555007935), ('monteros', 0.5731548070907593)]], [(u'hambre', 0.155), [('sufrimiento', 0.7107141017913818), ('cansancio', 0.6757653951644897), ('paludismo', 0.6607316732406616)]], [(u'juegos', 0.155), [('olimpicos', 0.7551369071006775), ('medallistas', 0.7083016633987427), ('istmicos', 0.7047864198684692)]], [(u'asesino', 0.12), [('vampiro', 0.7278130054473877), ('impostor', 0.7240990400314331), ('demonio', 0.7237610816955566)]], [(u'obsesionado', 0.12), [('obsesionada', 0.7906687259674072), ('familiarizado', 0.745010495185852), ('insatisfecho', 0.7041277289390564)]], [(u'historia', 0.105), [('literatura', 0.66166090965271), ('narracion', 0.6538480520248413), ('epopeya', 0.6430196762084961)]], [(u'nazis', 0.103), [('prusianos', 0.8135454058647156), ('aliados', 0.7837419509887695), ('alemanes', 0.7819315195083618)]], [(u'deportados', 0.103), [('evacuados', 0.8168916702270508), ('masacrados', 0.7857337594032288), ('enrolados', 0.7754632234573364)]]]\n",
        "[[(u'hambre', 0.227), [('sufrimiento', 0.7107141017913818), ('cansancio', 0.6757653951644897), ('paludismo', 0.6607316732406616)]], [(u'juegos', 0.227), [('olimpicos', 0.7551369071006775), ('medallistas', 0.7083016633987427), ('istmicos', 0.7047864198684692)]], [(u'chicos', 0.186), [('jovenes', 0.7667895555496216), ('ninos', 0.7601310014724731), ('muchachos', 0.7577528953552246)]], [(u'aunque', 0.124), [('pero', 0.7857924103736877), ('pues', 0.7317236661911011), ('obstante', 0.6768604516983032)]], [(u'seis', 0.124), [('cinco', 0.9624112844467163), ('ocho', 0.9555950164794922), ('tres', 0.9436907768249512)]], [(u'ver', 0.114), [('encontrar', 0.7320244908332825), ('observar', 0.7086633443832397), ('mirar', 0.7055149078369141)]], [(u'veces', 0.114), [('ocasiones', 0.6928472518920898), ('menudo', 0.5536725521087646), ('semanas', 0.5451972484588623)]], [(u'tenido', 0.114), [('habido', 0.864619255065918), ('sufrido', 0.7751103639602661), ('existido', 0.7664097547531128)]], [(u'batalla', 0.114), [('queronea', 0.7421445250511169), ('marignano', 0.7315524816513062), ('gaugamela', 0.7220394611358643)]]]\n",
        "\n",
        "Palabras del topic = modelos negocio metodo empresas lector lean chicos campos forma\n",
        "no encaja... \n",
        "forma\n",
        "\n",
        "Palabras del topic = modelos metodo arrakis dune negocio empresas lean juegos\n",
        "no encaja... \n",
        "juegos\n",
        "\n",
        "Palabras del topic = mercedes campos hambre juegos asesino obsesionado historia nazis deportados\n",
        "no encaja... \n",
        "mercedes\n",
        "\n",
        "Palabras del topic = hambre juegos chicos aunque seis ver veces tenido batalla\n",
        "no encaja... \n",
        "batalla\n"
       ]
      }
     ],
     "prompt_number": 154
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for palabras in palabrasTemas:\n",
      "    print \"\\n\"\n",
      "    print palabras\n",
      "    print \"Mas similar al conjunto entero... \"\n",
      "    print model.most_similar(positive = palabras, topn=5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "[u'modelos', u'negocio', u'metodo', u'empresas', u'lector', u'lean', u'chicos', u'campos']\n",
        "Mas similar al conjunto entero... \n",
        "[('disenadores', 0.6921409368515015), ('programadores', 0.6641051769256592), ('aprendizajes', 0.6542423963546753), ('mainframes', 0.6520909070968628), ('desarrolladores', 0.6475164294242859)]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "\n",
        "[u'modelos', u'metodo', u'arrakis', u'dune', u'negocio', u'empresas', u'lean']\n",
        "Mas similar al conjunto entero... \n",
        "[('mits', 0.6088240742683411), ('crowdsourcing', 0.5957372784614563), ('anticopia', 0.5941215753555298), ('multics', 0.5912716388702393), ('blitter', 0.5896362066268921)]\n",
        "\n",
        "\n",
        "[u'campos', u'hambre', u'juegos', u'asesino', u'obsesionado', u'historia', u'nazis', u'deportados']\n",
        "Mas similar al conjunto entero... \n",
        "[('samurais', 0.6948378086090088), ('sufrimientos', 0.6821528673171997), ('mafiosos', 0.6720846891403198), ('reproches', 0.671520471572876), ('asesinos', 0.6674761772155762)]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "\n",
        "[u'hambre', u'juegos', u'chicos', u'aunque', u'seis', u'ver', u'veces', u'tenido']\n",
        "Mas similar al conjunto entero... \n",
        "[('tontolinos', 0.6258419752120972), ('fangames', 0.6121869087219238), ('pillos', 0.6120515465736389), ('yoshis', 0.6046496629714966), ('regatear', 0.5994789004325867)]\n"
       ]
      }
     ],
     "prompt_number": 155
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for palabras in palabrasTemasProb:\n",
      "    print \"\\n\"\n",
      "    print palabras\n",
      "    print \"Mas similar al conjunto entero... \"\n",
      "    print model.most_similar(positive = palabras, topn=5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "[u'modelos', u'negocio', u'metodo', u'empresas']\n",
        "Mas similar al conjunto entero... \n",
        "[('tecnologias', 0.6871842741966248), ('transacciones', 0.6611473560333252), ('soluciones', 0.6522433161735535), ('encarecer', 0.6495350003242493), ('synopsys', 0.6461876630783081)]\n",
        "\n",
        "\n",
        "[u'modelos', u'metodo', u'arrakis', u'dune', u'negocio']\n",
        "Mas similar al conjunto entero... \n",
        "[('paradigma', 0.6483942270278931), ('concepto', 0.6422176957130432), ('diseno', 0.5953757166862488), ('criptoanalisis', 0.5951238870620728), ('multics', 0.5933825373649597)]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "\n",
        "[u'mercedes', u'campos', u'hambre', u'juegos']\n",
        "Mas similar al conjunto entero... \n",
        "[('gallos', 0.586725652217865), ('socavones', 0.5663720369338989), ('remedios', 0.5589828491210938), ('coghen', 0.5546586513519287), ('potros', 0.542555570602417)]\n",
        "\n",
        "\n",
        "[u'hambre', u'juegos', u'chicos', u'aunque', u'seis']\n",
        "Mas similar al conjunto entero... \n",
        "[('pillos', 0.6604799628257751), ('tontolinos', 0.6580052375793457), ('novios', 0.6554449796676636), ('kushanos', 0.6412086486816406), ('descansos', 0.6219860315322876)]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 156
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#1 /bookstore/MR MERCEDES.txt\n",
      "#2 /bookstore/LOS \u00daLTIMOS ESPA\u00d1OLES DE MAUTHAUSEN.txt\n",
      "#3 /bookstore/JUEGOS DEL HAMBRE 3 SINSAJO.txt\n",
      "#4 /bookstore/DUNE 1.txt\n",
      "#5 /bookstore/BUENOS DIAS PRINCESA.txt\n",
      "#6 /bookstore/GENERACION DE MODELOS DE NEGOCIO.txt\n",
      "#7 /bookstore/EL METODO DE LEAN STARTUP.txt\n",
      "bookNames = ['MR MERCEDES.txt','LOS \u00daLTIMOS ESPA\u00d1OLES DE MAUTHAUSEN.txt','JUEGOS DEL HAMBRE 3 SINSAJO.txt','DUNE 1.txt','BUENOS DIAS PRINCESA.txt','GENERACION DE MODELOS DE NEGOCIO.txt','EL METODO DE LEAN STARTUP.txt']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 142
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for doc, name in zip(corpus_lsi, bookNames): # both bow->tfidf and tfidf->lsi transformations are actually executed here, on the fly\n",
      "    print(name)\n",
      "    print(doc)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "MR MERCEDES.txt\n",
        "[(0, 0.24996153935121546), (1, -0.31874333415377804), (2, 0.60275509907415015), (3, 0.27477674754552373)]\n",
        "LOS \u00daLTIMOS ESPA\u00d1OLES DE MAUTHAUSEN.txt\n",
        "[(0, 0.36073345338639395), (1, -0.22610151354662825), (2, 0.51309608012475316), (3, 0.07158546258452321)]\n",
        "JUEGOS DEL HAMBRE 3 SINSAJO.txt\n",
        "[(0, 0.22545065212674681), (1, -0.32911180743443968), (2, -0.49675911516703491), (3, 0.70573845365900345)]\n",
        "DUNE 1.txt\n",
        "[(0, 0.20599900777690938), (1, -0.54403197387061419), (2, -0.3160386925363351), (3, -0.21180637236541383)]\n",
        "BUENOS DIAS PRINCESA.txt\n",
        "[(0, 0.40128512653996001), (1, -0.32565171055364583), (2, -0.13575066657087118), (3, -0.59630042508957048)]\n",
        "GENERACION DE MODELOS DE NEGOCIO.txt\n",
        "[(0, 0.59256976489188029), (1, 0.39207884821102318), (2, -0.1535701049546922), (3, -0.013345325007044717)]\n",
        "EL METODO DE LEAN STARTUP.txt\n",
        "[(0, 0.53591431160670722), (1, 0.45874794595887153), (2, -0.024598084222012203), (3, 0.069433386735191643)]\n"
       ]
      }
     ],
     "prompt_number": 143
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}