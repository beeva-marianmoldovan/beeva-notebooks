{
 "metadata": {
  "name": "",
  "signature": "sha256:05d4b57995c1688d0554b40bae3605d102939c758ef77b6b006c1c3dc879fe6e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Creando el modelo"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re, unicodedata\n",
      "from gensim import models\n",
      "import logging, string\n",
      "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Despu\u00e9s de inicializar las variables..."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Preprocesamiento de datos >> los almacena en un archivo (txt)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "S\u00f3lo ejecutar\u00e9 esto la primera vez, luego leer\u00e9 el archivo preprocesado (es_dataprocYahoo.txt)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fileDataRAW = '/home/nievesabalos/Escritorio/nlp/datasets/yahoo/code/es_dataYahooQA.txt' #txt con el texto plano\n",
      "fileDataProcessed = '/home/nievesabalos/Escritorio/nlp/datasets/yahoo/code/es_dataprocYahoo.txt'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# ---------------------------------------------------\n",
      "# 1. INPUT DATA\n",
      "print \"Fichero RAW a limpiar y preprocesar:\"\n",
      "print fileDataRAW\n",
      "\n",
      "def clean(x):\n",
      "   x = unicodedata.normalize('NFKD', x).encode('ascii','ignore').lower()\n",
      "   replace_punctuation = string.maketrans(string.punctuation, ' '*len(string.punctuation))\n",
      "   x = x.translate(replace_punctuation)\n",
      "   x = re.sub('@%$&[\\n/:!,;)()_?\u00bf\u00a1<>]', ' ', x)\n",
      "   x = re.sub(' - ', ' ', x)\n",
      "   x = re.sub(' +',' ', x).strip()\n",
      "   return x\n",
      "    \n",
      "sentences = []\n",
      "with open(fileDataRAW, 'r') as fileData:\n",
      "    for lineas in fileData:\n",
      "        #Formatear linea si hace falta aqu\u00ed\n",
      "        lineArray = lineas.split(\".\")\n",
      "        for line in lineArray:\n",
      "            if len(line) > 1:\n",
      "                line = line.decode('utf-8')\n",
      "                line = clean(line) # \u00bf? problemas con gensim y tildes y e\u00f1es...\n",
      "                if len(line) > 1:\n",
      "                    sentences.append(line)\n",
      "       \n",
      "    print \"Cierro fichero.\"\n",
      "    fileData.close()\n",
      "\n",
      "with open(fileDataProcessed, 'a') as fileData:\n",
      "    print \"Almaceno los datos procesados.\"\n",
      "    for frase in sentences:\n",
      "        fileData.write(frase)\n",
      "        fileData.write(\"\\n\")\n",
      "    print \"Cierro fichero.\"\n",
      "    fileData.close()    \n",
      "    \n",
      "print \"\\nFrases a analizar con doc2vec:\"             \n",
      "print len(sentences)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fichero RAW a limpiar y preprocesar:\n",
        "/home/nievesabalos/Escritorio/nlp/datasets/yahoo/code/es_dataYahooQA.txt\n",
        "Cierro fichero."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Almaceno los datos procesados.\n",
        "Cierro fichero."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Frases a analizar con doc2vec:\n",
        "9379360\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sentences = models.doc2vec.LabeledLineSentence(fileDataProcessed)\n",
      "#print sentences[0:50]\n",
      "# ejemplo: sentence = LabeledSentence(words=[u'some', u'words', u'here'], labels=[u'SENT_1'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#for frase in sentences:\n",
      "#    print frase\n",
      "    \n",
      "print type(sentences)    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<class 'gensim.models.doc2vec.LabeledLineSentence'>\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# m\u00e9todo que dado un label, me da el conjunto de palabras asociado:\n",
      "# \"SENT_5550\" >> ?\n",
      "\n",
      "def find(label):\n",
      "    for frase in sentences:\n",
      "        #print frase.labels\n",
      "        if label == frase.labels[0]:\n",
      "            return frase.words\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print find(\"SENT_5550\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[u'hace', u'5', u'anos', u'me', u'diagnosticaron', u'cancer', u'pulmonar', u'y', u'si', u'bien', u'es', u'cierto', u'duele', u'muchisimo', u'me', u'dieron', u'tres', u'meses', u'de', u'vida', u'y', u'creo', u'que', u'el', u'dolor', u'emocional', u'depende', u'de', u'como', u'veas', u'la', u'vida', u'y', u'la', u'muerte', u'no', u'me', u'da', u'miedo', u'morir', u'me', u'da', u'miedo', u'ser', u'mediocre', u'sigo', u'aqui', u'por', u'un', u'gran', u'esfuerzo', u'de', u'alguien', u'pero', u'jamas', u'le', u'dije', u'a', u'nadie', u'que', u'iba', u'a', u'morir', u'deseaba', u'que', u'me', u'trataran', u'con', u'dignidad', u'no', u'con', u'lastima', u'para', u'mi', u'el', u'dolor', u'fisico', u'era', u'peor', u'pero', u'para', u'quien', u'me', u'salvo', u'la', u'vida', u'el', u'emocional', u'era', u'peor', u'si', u'bien', u'era', u'humillante', u'que', u'me', u'ayudaran', u'hasta', u'pararme', u'no', u'dejo', u'de', u'pensar', u'que', u'los', u'guerreros', u'luchan', u'hasta', u'la', u'muerte', u'no', u'importa', u'cuanto', u'duela']\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Creo el modelo"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# ---------------------------------------------------\n",
      "# 2. CREATE MODEL\n",
      "# train doc2vec  -  tutorial: http://radimrehurek.com/2014/12/doc2vec-tutorial/ \n",
      "# parametros por defecto:\n",
      "# sentences=None, size=300, alpha=0.025, window=8, min_count=5, sample=0, \n",
      "# seed=1, workers=1, min_alpha=0.0001, dm=1, hs=1, negative=0, dm_mean=0, train_words=True, train_lbls=True, **kwargs\n",
      "\n",
      "# Doc2Vec learns representations for words and labels simultaneously. If you wish to only learn representations for words,\n",
      "# you can use the flag train_lbls=False in your Doc2Vec class. Similarly, if you only wish to learn representations for\n",
      "# labels and leave the word representations fixed, the model also has the flag train_words=False.\n",
      "\n",
      "model = models.Doc2Vec(sentences, size=300, workers=2)\n",
      "print \"\\n modelo doc2vec creado!\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Almaceno el modelo"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Ficheros del modelo en diferentes formatos\n",
      "fileModel = '/home/nievesabalos/Escritorio/nlp/datasets/yahoo/code/modelYahoo.doc2vec'  #.model\n",
      "fileModelBin = '/home/nievesabalos/Escritorio/nlp/datasets/yahoo/code/modelYahoo.model.doc2vec.bin' #.bin\n",
      "fileModelTxt = '/home/nievesabalos/Escritorio/nlp/datasets/yahoo/code/modelYahoo.model.doc2vec.txt' #.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# ---------------------------------------------------\n",
      "# 4. SAVE MODEL\n",
      "print \"\\nGuardo el modelo en .model (formato doc2vec):\"  \n",
      "print fileModel \n",
      "model.save(fileModel)\n",
      "\n",
      "\n",
      "print \"\\nGuardo el modelo en .bin:\"  \n",
      "print fileModelBin \n",
      "model.save_word2vec_format(fileModelBin, binary=True)\n",
      "print \"\\n...y guardo el modelo en .txt:\"  \n",
      "print fileModelTxt \n",
      "model.save_word2vec_format(fileModelTxt, binary=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Tests"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print model[\"novio\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print model.most_similar(\"SENT_7643\")\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print model.most_similar(\"novio\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print model.most_similar(\"SENT_5550\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}